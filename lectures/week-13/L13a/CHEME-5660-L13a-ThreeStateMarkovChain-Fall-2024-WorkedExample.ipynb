{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1293aec-55db-45f8-866c-13da40b367bb",
   "metadata": {},
   "source": [
    "## Example: Three-State Markov Model\n",
    "In this example, let's construct and then sample a three-state Markov model, with three states $\\mathcal{S}\\equiv\\left\\{1,2,3\\right\\}$, shown below:\n",
    "<div>\n",
    "    <center>\n",
    "        <img src=\"figs/Fig-ThreeState-MM-Schematic.svg\" width=\"580\"/>\n",
    "    </center>\n",
    "</div>\n",
    "where the $p_{ij}$ values describe the probability of moving from state $s_{i}$ to state $s_{j}$ in the next time step. The states in the model could represent many things, for example an investors attitide toward an asset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbaa043-d87e-403e-a2f7-69475d5bbd7f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Setup\n",
    "Let's load some required packages for the example by calling the `include(...)` function on our [initialization file `Include.jl`](Include.jl):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec70e14c-9cdf-45a6-ba16-b955ea8967b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"Include.jl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6eef80-acde-4902-b589-56f7d018baca",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Prerequisites \n",
    "Before we start this example, let's set up the `iterate(...)` method and specify some constants. We'll use the `iterate(...)` method to compute the stationary distribution $\\pi$.\n",
    "```julia\n",
    "iterate(P::Array{Float64,2}; \n",
    "        maxcount::Int = 100, ϵ::Float64 = 0.1) -> Array{Float64,2}\n",
    "```\n",
    "> Iteratively computes a stationary distribution. Computation stops if ||P_new - P|| < ϵ or the max number of iterations is hit. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2eaa59-5562-49f2-9c61-b736368e4431",
   "metadata": {},
   "source": [
    "`Unhide` the code block below to see the implementation of the `iterate(...)` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2dc9d7b-3bf0-48c5-9e0e-08169cd4833d",
   "metadata": {},
   "outputs": [],
   "source": [
    "function iterate(P::Array{Float64,2}; \n",
    "        maxcount::Int = 100, ϵ::Float64 = 0.1)::Array{Float64,2}\n",
    "\n",
    "    # initialize -\n",
    "    counter = 1; # initialize the iteration counter\n",
    "    is_ok_to_stop = false; # flag for while loop\n",
    "    P_new = nothing; # initialize P_new matrix\n",
    "    \n",
    "    # main loop - iterate until the difference ||P_new - P|| <= ϵ -or- we run out of iterations\n",
    "    while (is_ok_to_stop == false)\n",
    "        P_new = P^(counter+1); # compute new P matrix by raising to counter + 1 power\n",
    "        if (norm(P_new - P) <= ϵ || counter >= maxcount)\n",
    "            is_ok_to_stop = true;\n",
    "        end\n",
    "        counter += 1; # update the counter\n",
    "    end\n",
    "\n",
    "    # return -\n",
    "    return P_new;\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4417a3b2-49b2-4c9a-b430-2b851c8d5f88",
   "metadata": {},
   "source": [
    "#### Constants\n",
    "In the simulations below, we'll need some constant values that we set here. In particular, we set a value for the `number_of_hidden_states` variable, the `number_of_simulation_steps` variable (the number of steps that we take in a Markov Chain), and the `number_of_samples ` variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2583bfcc-b581-4c01-bd98-ecb18c4d7046",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_hidden_states = 3; # how many states do we have?\n",
    "number_of_simulation_steps = 10000; # number of simulation steps\n",
    "number_of_samples = 10000; # number of samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c90be8d-b149-4ca8-80b8-400de616b919",
   "metadata": {},
   "source": [
    "## Task 1: Setup transition matrix for a three-state Markov Model\n",
    "In this task, we'll set up the transition matrix $\\mathbf{P}$ for the three-state [Markov chain model](https://en.wikipedia.org/wiki/Markov_chain) shown above.\n",
    "* In this example we have three states $\\mathcal{S}=\\left\\{1,2,3\\right\\}$ where the probability of moving between state $s_{i}\\rightarrow{s_{j}}$ in the next time step is denoted as $p_{ij}\\in\\mathcal{P}$. The transition matrix is a $|\\mathcal{S}|\\times|\\mathcal{S}|$ matrix with non-negative elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99defaab-7efe-44f0-832b-6cc1f81c9779",
   "metadata": {},
   "outputs": [],
   "source": [
    "P = [\n",
    "    0.05 0.95 0.0 ; # possible next state from state 1 \n",
    "    0.6 0.2 0.2 ; # possible next state from state 2\n",
    "    0.0 0.3 0.7 ; # possible next state from state 3\n",
    "];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b3e5e4-9ff9-4625-971b-f8e64dd9beb4",
   "metadata": {},
   "source": [
    "### Check: do the rows of the transition matrix $\\mathbf{P}$ sum to `1`?\n",
    "We know that the rows of the transition matrix $\\mathbf{P}$ must sum to `1`, i.e., if we are in state $s_{i}\\in\\mathcal{S}$ at time $t$, then at time $t+1$ we have to be in $s_{j}\\in\\mathcal{S}$. \n",
    "* Let's check if the transition matrix $\\mathbf{P}$ meets this criteria using the [@assert macro](https://docs.julialang.org/en/v1/base/base/#Base.@assert) by iterating over the rows of the transition matrix $\\mathbf{P}$ and checking the sum of each row. If any row does not meet this criterion, an [AssertionError](https://docs.julialang.org/en/v1/base/base/#Core.AssertionError) will be thrown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d531b4f1-5dc6-4a9e-9a81-1034d56d0158",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i ∈ 1:number_of_hidden_states\n",
    "    @assert sum(P[i,:]) == 1\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfaedb7-81f6-4563-86aa-983fc6a9f5c6",
   "metadata": {},
   "source": [
    "## Task 2: Compute the stationary distribution $\\bar{\\pi}$\n",
    "In this task, we'll compute the stationary distribution $\\pi$ for our three-state example [Markov chain](https://en.wikipedia.org/wiki/Markov_chain) shown above.\n",
    "\n",
    "We'll compute the stationary distribution $\\bar{\\pi}$ using the iterative `iterate(...)` method. During each iteration, we compute the matrix power of transition matrix $\\mathbf{P}$. We continue to iterate until we hit one of two possible conditions:\n",
    "* The  `counter == maxcount,` at this point, the iteration stops, and the matrix $\\mathbf{P}^{\\star}$ is returned\n",
    "* The iteration stops because difference between subsequent powers of the matrix $\\mathbf{P}$ is smaller than some specified threshold $\\epsilon$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6ba76de-b22a-4471-81f5-fea20b069d93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×3 Matrix{Float64}:\n",
       " 0.274809  0.435115  0.290076\n",
       " 0.274809  0.435115  0.290076\n",
       " 0.274809  0.435115  0.290076"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "π̄ = iterate(P, ϵ = 0.0000001) # this gives the stationary distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69023b2f-7c8e-45fd-94f4-2ab65ed00494",
   "metadata": {},
   "source": [
    "### Check: Is the rank condition on the stationary distribution $\\bar{\\pi}$ correct?\n",
    "Once we reach the stationary distribution, the rank of the stationary distribution $\\bar{\\pi}$ should be equal to `1`. Let's check whether this condition is true using the [@assert macro](https://docs.julialang.org/en/v1/base/base/#Base.@assert). \n",
    "* If we do not meet this criterion, an [AssertionError](https://docs.julialang.org/en/v1/base/base/#Core.AssertionError) will be thrown, and we should try to use more iterations or a tighter numerical tolerance value for $\\epsilon$. We'll compute the rank using the [rank function](https://docs.julialang.org/en/v1/stdlib/LinearAlgebra/#LinearAlgebra.rank) which is exported by the [Julia Statistics package](https://docs.julialang.org/en/v1/stdlib/Statistics/#Statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dcbfd526-2732-43b8-b272-d635441c3fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@assert rank(π̄) == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851525ae-61cb-467a-956c-731a4f615d4f",
   "metadata": {},
   "source": [
    "### Deeper: Compute Stationary Distribution $\\bar{\\pi}$ using the Left Matrix Vector Product\n",
    "We can also approach the computation of the stationary distribution $\\bar{\\pi}$ by directly iterating the expression:\n",
    "$$\n",
    "\\begin{equation*}\n",
    "\\pi_{n+1} = \\pi_{1}\\cdot\\mathbf{P}^{n}\\quad\\,n=1,2,\\dots\n",
    "\\end{equation*}\n",
    "$$\n",
    "where $\\pi_{1}$ is our initial belief of the state distribution, and $\\mathbf{P}$ is the transition matrix. As $n\\rightarrow\\infty$, i.e., as we do more iterations, the difference between subsequent iterations should become small $||\\pi_{n+1}-\\pi_{n}||<\\epsilon$ for a non-periodic Markov chain, where $\\pi_{n}\\rightarrow\\bar{\\pi}$ as $n\\rightarrow\\infty$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8db828ae-3f4e-4586-baa8-065d9d280182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 1.0, 0.0]\n",
      "[0.6, 0.2, 0.2]\n",
      "[0.15, 0.6699999999999999, 0.18]\n",
      "[0.4094999999999999, 0.33049999999999996, 0.26]\n",
      "[0.21877499999999994, 0.533125, 0.2481]\n",
      "[0.3308137499999999, 0.38889124999999997, 0.28029499999999996]\n",
      "[0.2498754374999999, 0.4761398124999999, 0.27398475]\n",
      "[0.2981776593749999, 0.4148050531249999, 0.28701728749999994]\n",
      "[0.26379191484374986, 0.45233497328124994, 0.283873111875]\n",
      "[0.2845905797109374, 0.4262312473203125, 0.2891781729687499]\n",
      "[0.2699682773777342, 0.442360752080078, 0.28767097054218743]\n",
      "[0.2789148651169334, 0.4312433050875194, 0.2898418297955468]\n",
      "[0.27269172630835825, 0.43817033181725473, 0.2891379418743867]\n",
      "[0.2765367854057707, 0.4334325889187073, 0.29003062567552157]\n",
      "[0.2738863926215128, 0.43640565162188016, 0.28970795575660657]\n",
      "[0.2755377106042036, 0.4343855900417952, 0.2900766993540006]\n",
      "[0.27440823955528726, 0.4356609528885528, 0.2899308075561595]\n",
      "[0.275116983710896, 0.43479926042208134, 0.2900837558670222]\n",
      "[0.2746354054387935, 0.43534611336987405, 0.2900184811913318]\n",
      "[0.2749394382938641, 0.43497840219822825, 0.29008215950790706]\n"
     ]
    }
   ],
   "source": [
    "π₁ = [0.0,1.0,0.0]; # initial state = state 2\n",
    "direct_state_distribution = Dict{Int,Array{Float64,1}}();\n",
    "direct_state_distribution[1] = π₁;\n",
    "for n = 2:number_of_simulation_steps\n",
    "    πᵢ = transpose(π₁)*(P)^(n-1)\n",
    "    direct_state_distribution[n] =  transpose(πᵢ)\n",
    "end\n",
    "foreach(i-> println(direct_state_distribution[i]), 1:20);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3175d003-f346-435c-bedf-d620f286768b",
   "metadata": {},
   "source": [
    "## Task 3: Sample from our Markov Model using a Categorical Distribution\n",
    "In this task, we compute a sequence of states for the three-state [Markov chain model](https://en.wikipedia.org/wiki/Markov_chain) and compare the frequency of those states to what we see for the stationary distribution $\\bar{\\pi}$.\n",
    "\n",
    "### Sampling\n",
    "We can get the dynamics, i.e., the sequences of states $s_{1},s_{2},\\dotsc$ predicted by the [Markov model](https://en.wikipedia.org/wiki/Markov_model) by sampling the transition probability matrix $\\mathbf{P}$ directly. We can do this using a [categorical distribution](https://en.wikipedia.org/wiki/Categorical_distribution), which models transition from state $i\\rightarrow{j}$ in the next time step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6145cf72-2025-48ca-ba51-04c01199a8b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Int64, Categorical{P} where P<:Real} with 3 entries:\n",
       "  2 => Categorical{Float64, Vector{Float64}}(support=Base.OneTo(3), p=[0.6, 0.2…\n",
       "  3 => Categorical{Float64, Vector{Float64}}(support=Base.OneTo(3), p=[0.0, 0.3…\n",
       "  1 => Categorical{Float64, Vector{Float64}}(support=Base.OneTo(3), p=[0.05, 0.…"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_probability_dictionary = Dict{Int,Categorical}();\n",
    "for i ∈ 1:number_of_hidden_states\n",
    "    state_probability_dictionary[i] = Categorical(P[i,:])\n",
    "end\n",
    "state_probability_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0c44d8-21ea-41ea-af74-d820674b3f55",
   "metadata": {},
   "source": [
    "Let's generate `number_of_simulation_steps` worth of dynamic data by sampling the `state_probability_dictionary.` We store these simulation results in the `simulation_dictionary` dictionary, where the `key` holds the time index and the `value` is the system's state, i.e., $s_{i}\\in\\mathcal{S}$.\n",
    "* We start by specifying an initial state `sᵢ = 1`. At each iteration of the loop, we pull out the [categorical distribution](https://en.wikipedia.org/wiki/Categorical_distribution) corresponding to the state $s_{i}$, i.e., the row in the transition matrix $\\mathbf{P}$ corresponding to state $s_{i}$. We then generate the state at the next step by drawing a sample from the categorical distribution using the `rand(...)` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e0e9f29-4eef-4486-be43-6e1d94f47729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soln: (t=1,s=1)\n",
      "Soln: (t=2,s=2)\n",
      "Soln: (t=3,s=1)\n",
      "Soln: (t=4,s=2)\n",
      "Soln: (t=5,s=2)\n",
      "Soln: (t=6,s=1)\n",
      "Soln: (t=7,s=2)\n",
      "Soln: (t=8,s=2)\n",
      "Soln: (t=9,s=1)\n",
      "Soln: (t=10,s=2)\n"
     ]
    }
   ],
   "source": [
    "simulation_dictionary = Dict{Int,Int}();\n",
    "sᵢ = 1; # harcode the start state: we also could draw from the stationary distribution\n",
    "simulation_dictionary[1] = sᵢ;\n",
    "for i ∈ 2:number_of_simulation_steps\n",
    "    \n",
    "    sᵢ = state_probability_dictionary[sᵢ] |> d -> rand(d); # get dcat for sᵢ, draw a sample -> next state\n",
    "    simulation_dictionary[i] = sᵢ;  # capture the next state at t = i\n",
    "    \n",
    "end\n",
    "foreach(i -> println(\"Soln: (t=$(i),s=$(simulation_dictionary[i]))\"), 1:10) # look at first 10 steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8e2db0-ec32-4e5d-9fde-e94495d7a36f",
   "metadata": {},
   "source": [
    "### Check: Do we recover the stationary distribution $\\bar{\\pi}$?\n",
    "Like any stable dynamic system, e.g., concentration balances in a steady-state reactor, if we wait long enough, the system should approach a steady state (assuming the steady state exists and is stable). By analogy, if we take enough time steps for our random dynamic system, the distribution of states should follow the stationary distribution $\\bar{\\pi}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7163e2fe-0625-485a-a006-a0980b44b53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "S = [simulation_dictionary[i] for i ∈ 1:number_of_simulation_steps]; # put the s_1, ...., s_n into a basket\n",
    "NS₁ = findall(x-> x == 1, S) |> length; # how many 1's in the basket?\n",
    "NS₂ = findall(x-> x == 2, S) |> length; # how many 2's in the basket?\n",
    "NS₃ = findall(x-> x == 3, S) |> length; # how many 3's in the basket?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76785601-7d5e-456b-ba75-72a1832ee147",
   "metadata": {},
   "source": [
    "We can compute the relative frequency (probability) of the states `s = 1`, `s = 2`, and `s = 3`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "179d038b-4b8d-4b1a-8820-c096e3fc97f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sampled probability (p₁,p₂,p₃) = (0.2801, 0.4309, 0.289)\n"
     ]
    }
   ],
   "source": [
    "PS1 = NS₁/number_of_simulation_steps;\n",
    "PS2 = NS₂/number_of_simulation_steps;\n",
    "PS3 = NS₃/number_of_simulation_steps;\n",
    "println(\"The sampled probability (p₁,p₂,p₃) = ($(PS1), $(PS2), $(PS3))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce93f933-9161-4864-9e87-49a4fd21a135",
   "metadata": {},
   "source": [
    "### What does it mean when we sample $\\bar{\\pi}$ directly?\n",
    "A common source of confusion is the meaning of the stationary distribution $\\bar{\\pi}$. \n",
    "\n",
    "Suppose we don't care about the system's dynamics (time behavior). Instead, we are only interested in the steady-state behavior, i.e., the stationary distribution. In that case, we can sample $\\bar{\\pi}$ directly, but if we do that, we lose all the information about the transitions, i.e., all the time behavior. To explore this, consider the following thought experiment:\n",
    "\n",
    "* __Thought experiment__: Suppose our three-state model represented investor mood. We gathered `20` investors together in a focus group, isolated them, but gave them access to the same sources of information, and watched their mood for many rounds, i.e., as $n\\rightarrow\\infty$. The long-term mood of each investor would be samples from the stationary distribution $\\bar{\\pi}$\n",
    "\n",
    "Let's implement this thought experiment. Create a [categorical distribution](https://en.wikipedia.org/wiki/Categorical_distribution) using the stationary probability of our Markov chain using the [Distributions.jl](https://github.com/JuliaStats/Distributions.jl) package, save this distribution in the variable `d`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d4fda571-3740-4c20-ab8c-f89c1b50f323",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Categorical(π̄[1,:]); # build a model of the stationary distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de683907-f518-43cb-8cc1-c72e0aace1e7",
   "metadata": {},
   "source": [
    "We can then generate samples from the [categorical distribution](https://en.wikipedia.org/wiki/Categorical_distribution) saved in the distribution `d` using the [rand function](https://docs.julialang.org/en/v1/stdlib/Random/#Base.rand). This allows us to `simulate` the long-time behavior encoded by our three-state Markov model, i.e., the moods of the investors in our focus group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6a99ae9e-789f-4f3e-bbd9-678a1d678007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20-element Vector{Int64}:\n",
       " 3\n",
       " 3\n",
       " 2\n",
       " 3\n",
       " 3\n",
       " 1\n",
       " 3\n",
       " 3\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 3\n",
       " 2"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand(d,20) # generate 20 samples from the stationary distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcef8696-4a77-44a0-bd48-5f9fc31391cb",
   "metadata": {},
   "source": [
    "### Wait, why are there illegal transitions?\n",
    "Sampling the stationary distribution $\\bar{\\pi}$ does __not give information about dynamics__. These samples do __not__ represent the transition of states between time steps. \n",
    "\n",
    "Instead, the stationary distribution $\\bar{\\pi}$ gives us the relative likelihood that we observed state $s_{i}\\in\\mathcal{S}$ as $n\\rightarrow\\infty$ (at long times). If we want information about the dynamics, we need to sample the chain directly __not__ the stationary distribution."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.1",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
